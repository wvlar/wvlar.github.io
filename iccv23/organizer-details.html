<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <title>VLAR 2023 - Vision-and-Language Algorithmic Reasoning</title>
  <meta content="width=device-width, initial-scale=1.0" name="viewport">
  <meta content="" name="keywords">
  <meta content="" name="description">

  <!-- Favicons -->
  <link href="img/iccv23.png" rel="icon">
  <link href="img/iccv23.png" rel="apple-touch-icon">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,700,700i|Raleway:300,400,500,700,800" rel="stylesheet">

  <!-- Bootstrap CSS File -->
  <link href="lib/bootstrap/css/bootstrap.min.css" rel="stylesheet">

  <!-- Libraries CSS Files -->
  <link href="lib/font-awesome/css/font-awesome.min.css" rel="stylesheet">
  <link href="lib/animate/animate.min.css" rel="stylesheet">
  <link href="lib/venobox/venobox.css" rel="stylesheet">
  <link href="lib/owlcarousel/assets/owl.carousel.min.css" rel="stylesheet">

  <!-- Main Stylesheet File -->
  <link href="css/style.css" rel="stylesheet">

  <!-- =======================================================
    Theme Name: TheEvent
    Theme URL: https://bootstrapmade.com/theevent-conference-event-bootstrap-template/
    Author: BootstrapMade.com
    License: https://bootstrapmade.com/license/
  ======================================================= -->
</head>

<body>

  <!--==========================
    Header
  ============================-->
  <header id="header" class="header-fixed">
    <div class="container">

      <div id="logo" class="pull-left">
        <!-- Uncomment below if you prefer to use a text logo -->
        <!-- <h1><a href="#main">C<span>o</span>nf</a></h1>-->
        <!-- <a href="index.html#intro" class="scrollto"><img src="img/logo.png" alt="" title=""></a> -->
        <a href="index.html#intro" class="scrollto"><p style="font-size:30px;color:white">VLAR 2023</p></a>
      </div>

      <nav id="nav-menu-container">
        <ul class="nav-menu">
          <li class="menu-active"><a href="index.html#intro">Home</a></li>
          <li><a href="index.html#about">About</a></li>
          <li><a href="index.html#speakers">Speakers</a></li>
          <li><a href="index.html#schedule">Schedule</a></li>
		  <li><a href="index.html#submission">Submission</a></li>
		  <!--<li><a href="index.html#accepted_work">Accepted Work</a></li>-->
          <li><a href="index.html#venue">Venue</a></li>
          <!-- <li><a href="#hotels">Hotels</a></li> -->
          <!-- <li><a href="#gallery">Gallery</a></li> -->
          <li><a href="index.html#supporters">Sponsors</a></li>
          <!-- <li><a href="#contact">Contact</a></li> -->
          <li><a href="index.html#organizers">Contact</a></li>
		  <li><a class="btn navbar-btn mx-2 text-white btn-outline-light" href="https://cmt3.research.microsoft.com/VLAR2023" target="_blank" rel="noopener noreferrer">CMT</a></li>
		  <li><a class="btn navbar-btn mx-2 text-white btn-outline-light" href="https://eval.ai/web/challenges/challenge-page/2088/overview" target="_blank" rel="noopener noreferrer">Challenge</a></li>
		  <li><a class="btn navbar-btn mx-2 text-white btn-outline-light" href="https://smartdataset.github.io/smart101/" target="_blank" rel="noopener noreferrer">SMART-101</a></li>
          <!-- <li><a href="../index.html#VASBSD_series">VASBSD Series</a></li> -->
          <!-- <li class="buy-tickets"><a href="#buy-tickets">Buy Tickets</a></li> -->
        </ul>
      </nav><!-- #nav-menu-container -->
    </div>
  </header><!-- #header -->

  <main id="main" class="main-page">

    <!--==========================
      Organizer Details Section
    ============================-->
    <section id="organizers-details" class="wow fadeIn">
      <div class="container">
        <div class="section-header">
          <h2>Organizer Details</h2>
          <!-- <p>TBD</p> -->
        </div>

		<div class="row">
          <div class="col-md-6">
            <a href="http://users.cecs.anu.edu.au/~cherian/" target="_blank" rel="noopener noreferrer"><img src="img/organizers/Anoop_Cherian.jpg" alt="Anoop Cherian" class="img-fluid" style="width:55%;padding-bottom: 0px"></a>
          </div>
          <div class="col-md-6">
            <div class="details">
              <h2 id="Anoop_Cherian"><a href="http://users.cecs.anu.edu.au/~cherian/" target="_blank" rel="noopener noreferrer">Anoop Cherian</a></h2>
              <p>Mitsubishi Electric Research Laboratories (MERL)</p>
              <div class="social">
                <!-- <a href=""><i class="fa fa-twitter"></i></a> -->
                <!-- <a href=""><i class="fa fa-facebook"></i></a> -->
                <!-- <a href=""><i class="fa fa-google-plus"></i></a> -->
                <a href="https://www.linkedin.com/in/anoop-cherian-4678a04/" target="_blank" rel="noopener noreferrer"><i class="fa fa-linkedin"></i></a>
              </div>
              <p>Bio:<br>Dr. Anoop Cherian is a Senior Principal Research Scientist with Mitsubishi Electric Research Labs (MERL) in Cambridge, MA and an adjunct Senior Lecturer with the Australian National University (ANU), Canberra, Australia. He was a former Research Fellow with the Australian Center for Robotic Vision (ACRV) at ANU, and a Postdoctoral Fellow with the LEAR project team at Inria, Grenoble, France. Anoop received his MS and PhD degrees in 2010 and 2013 respectively from the University of Minnesota, Minneapolis, and B.Tech from National Institute of Technology, Calicut, India. Anoop has broad interests in the areas of multimodal and embodied AI, neuro-symbolic reasoning, generative models, robotics, and optimization. Anoop has organized several workshops at computer vision venues in the past,  including the Deep Declarative Networks Workshop at CVPR 2020, Tensor Methods in Computer Vision (TMCV) at CVPR 2017, Robotic Vision Summer School (RVSS 2017), and Visually Grounded Interaction and Language (VIGIL) at NeurIPS 2018, among others.</p>
            </div>
          </div>  
        </div>

		<p></p>

        <div class="row">
          <div class="col-md-6">
            <a href="http://www.merl.com/people/kpeng"  target="_blank" rel="noopener noreferrer"><img src="img/organizers/Kuan-Chuan_Peng.jpg" alt="Kuan-Chuan Peng" class="img-fluid" style="width:55%;padding-bottom: 0px"></a>
          </div>
          <div class="col-md-6">
            <div class="details">
              <h2 id="Kuan-Chuan_Peng"><a href="http://www.merl.com/people/kpeng" target="_blank" rel="noopener noreferrer">Kuan-Chuan Peng</a></h2>
              <p>Mitsubishi Electric Research Laboratories (MERL)</p>
              <div class="social">
                <!-- <a href=""><i class="fa fa-twitter"></i></a> -->
                <a href="https://www.facebook.com/LynxPeng" target="_blank" rel="noopener noreferrer"><i class="fa fa-facebook"></i></a>
                <!-- <a href=""><i class="fa fa-google-plus"></i></a> -->
                <a href="https://www.linkedin.com/in/kuan-chuan-peng-8344817a/" target="_blank" rel="noopener noreferrer"><i class="fa fa-linkedin"></i></a>
              </div>
              <p>Bio:<br>Dr. Kuan-Chuan Peng is an IEEE Senior Member and a Principal Research Scientist at Mitsubishi Electric Research Labs (MERL) in Cambridge, MA. He received his Ph.D. degree in Electrical and Computer Engineering from Cornell University in 2016. He received a B.S. degree in Electrical Engineering and an M.S. degree in Computer Science from National Taiwan University in 2009 and 2012 respectively. His expertise includes domain adaptation, anomaly detection, attention modeling, and fundamental computer vision and machine learning problems. He organized: (1) 2022 Workshop on Artificial Intelligence with Biased or Scarce Data in conjunction with AAAI 2022. (2) 2022 Workshop on Vision with Biased or Scarce Data in conjunction with ECCV 2022. (3) 2020, 2021, 2022, and 2023 Workshop on Fair, Data-Efficient and Trusted Computer Vision in conjunction with CVPR in 2020, 2021, 2022, and 2023. (4) 2020 and 2021 Workshop on Vision Applications and Solutions to Biased or Scarce Data in conjunction with WACV in 2020 and 2021. (5) 2018 and 2019 Workshop on Vision with Biased or Scarce Data in conjunction with CVPR in 2018 and 2019.</p>
            </div>
          </div>  
        </div>
		
		<p></p>
		
		<div class="row">
          <div class="col-md-6">
            <a href="https://www.merl.com/people/slohit" target="_blank" rel="noopener noreferrer"><img src="img/organizers/Suhas_Lohit.jpg" alt="Suhas Lohit" class="img-fluid" style="width:55%;padding-bottom: 0px"></a>
          </div>
          <div class="col-md-6">
            <div class="details">
              <h2 id="Suhas_Lohit"><a href="https://www.merl.com/people/slohit" target="_blank" rel="noopener noreferrer">Suhas Lohit</a></h2>
              <p>Mitsubishi Electric Research Laboratories (MERL)</p>
              <div class="social">
                <!-- <a href=""><i class="fa fa-twitter"></i></a> -->
                <!-- <a href=""><i class="fa fa-facebook"></i></a> -->
                <!-- <a href=""><i class="fa fa-google-plus"></i></a> -->
                <a href="https://www.linkedin.com/in/suhaslohit/" target="_blank" rel="noopener noreferrer"><i class="fa fa-linkedin"></i></a>
              </div>
              <p>Bio:<br>Dr. Suhas Lohit is a Principal Research Scientist at Mitsubishi Electric Research Labs (MERL) in Cambridge, MA, USA. Before coming to MERL, Suhas received his Ph.D degree in Electrical Engineering from Arizona State University in 2019. His research interests include computer vision, computational imaging and deep learning. Recently, his research focus has been on creating hybrid model- and data-driven neural architectures for various applications in imaging and vision.</p>
            </div>
          </div>  
        </div>
		
		<p></p>
		
		<div class="row">
          <div class="col-md-6">
            <a href="https://ram81.github.io/" target="_blank" rel="noopener noreferrer"><img src="img/organizers/Ram_Ramrakhya.jpg" alt="Ram Ramrakhya" class="img-fluid" style="width:55%;padding-bottom: 0px"></a>
          </div>
          <div class="col-md-6">
            <div class="details">
              <h2 id="Ram_Ramrakhya"><a href="https://ram81.github.io/" target="_blank" rel="noopener noreferrer">Ram Ramrakhya</a></h2>
              <p>Georgia Tech</p>
              <div class="social">
                <!-- <a href=""><i class="fa fa-twitter"></i></a> -->
                <!-- <a href=""><i class="fa fa-facebook"></i></a> -->
                <!-- <a href=""><i class="fa fa-google-plus"></i></a> -->
                <a href="https://www.linkedin.com/in/ram-ramrakhya-617410118/" target="_blank" rel="noopener noreferrer"><i class="fa fa-linkedin"></i></a>
              </div>
              <p>Bio:<br>Ram Ramrakhya is a MS CS student at Georgia Institute of Technology in Atlanta, GA, USA. His research interests include EmbodiedAI, and Reinforcement Learning. His research focuses on leveraging large-scale human demonstrations to learn semantic navigation and interaction skills. Previously, he spent a year working as a Research Intern in Computer Vision and Machine Learning Perception Lab at Georgia Tech advised by Prof. Dhruv Batra and Prof. Devi Parikh.</p>
            </div>
          </div>  
        </div>
		
		<p></p>
		
		<div class="row">
          <div class="col-md-6">
            <a href="https://sites.google.com/view/hongluzhou/" target="_blank" rel="noopener noreferrer"><img src="img/organizers/Honglu_Zhou.png" alt="Honglu Zhou" class="img-fluid" style="width:55%;padding-bottom: 0px"></a>
          </div>
          <div class="col-md-6">
            <div class="details">
              <h2 id="Honglu_Zhou"><a href="https://sites.google.com/view/hongluzhou/" target="_blank" rel="noopener noreferrer">Honglu Zhou</a></h2>
              <p>NEC Laboratories America, Inc.</p>
              <div class="social">

                <!-- <a href=""><i class="fa fa-twitter"></i></a> -->
                <!-- <a href=""><i class="fa fa-facebook"></i></a> -->
                <!-- <a href=""><i class="fa fa-google-plus"></i></a> -->
                <a href="https://www.linkedin.com/in/honglu-zhou-21058a169/" target="_blank" rel="noopener noreferrer"><i class="fa fa-linkedin"></i></a>
              </div>
              <p>Bio:<br>Dr. Honglu Zhou is a researcher in the Machine Learning Department at NEC Laboratories America, Inc. She received her Ph.D. degree at Rutgers University in the Computer Science Department, under the supervision of Prof. Mubbasir Kapadia. She was a member of the Intelligent Visual Interfaces Lab. Her work was published in numerous renowned conferences (CVPR, ICLR, ECCV, SIGIR, IJCAI) and journals (Springer The Visual Computer, IEEE Computer Graphics and Applications). Her work has been recognized with a Best Paper Award from CIKM 2022. She has done multiple internships and collaborated with researchers from Salesforce Research, NEC Laboratories America, Google YouTube, DeepMind, and Google Research. Honglu is passionate about next-generation machine intelligence. Her research interests lie in the areas of video understanding, machine reasoning, multimodality and generative models. Her goal is to tackle fundamental problems in high-level semantic analysis and reasoning by developing effective and efficient methods, especially for videos and human behavior sequences, so that machines are able to interpret and interact with the dynamic visual world that we humans live in.</p>
            </div>
          </div>  
        </div>
		
		<p></p>
	
		<div class="row">
          <div class="col-md-6">
            <a href="http://www.mit.edu/~k2smith/" target="_blank" rel="noopener noreferrer"><img src="img/organizers/Kevin_Smith.jpg" alt="Kevin Smith" class="img-fluid" style="width:55%;padding-bottom: 0px"></a>
          </div>
          <div class="col-md-6">
            <div class="details">
              <h2 id="Kevin_Smith"><a href="http://www.mit.edu/~k2smith/" target="_blank" rel="noopener noreferrer">Kevin Smith</a></h2>
              <p>MIT</p>
              <div class="social">
                <a href="https://twitter.com/realkevinsmith" target="_blank" rel="noopener noreferrer"><i class="fa fa-twitter"></i></a>
                <!-- <a href=""><i class="fa fa-facebook"></i></a> -->
                <!-- <a href=""><i class="fa fa-google-plus"></i></a> -->
                <a href="https://www.linkedin.com/in/kevin-smith-4636944/" target="_blank" rel="noopener noreferrer"><i class="fa fa-linkedin"></i></a>
              </div>
              <p>Bio:<br>Dr. Kevin Smith is a research scientist at the Computational Cognitive Sciences lab at MIT, whose research reverse engineers the processes people use to understand and reason about the physical world. His work has been recognized with a best paper award from Robotics: Science and Systems 2018, as well as for the best Perception & Action model at the Cognitive Sciences Society 2012. He has previously organized workshops and symposia at NeurIPS (Modeling the Physical World: Perception, Learning, and Control), 2018; Physical Reasoning and Inductive Biases for the Real World, 2021), ECCV (First Challenge on Machine Visual Common Sense: Perception, Prediction, Planning, 2022), and the Cognitive Sciences Society (The Origins of Common Sense in Humans and Machines, 2020; Strategies and Representations in Physical Inference, 2018).</p>
            </div>
          </div>  
        </div>
		
		<p></p>
		
		<div class="row">
          <div class="col-md-6">
            <a href="https://www.merl.com/people/tmarks" target="_blank" rel="noopener noreferrer"><img src="img/organizers/Tim_Marks.jpg" alt="Tim Marks" class="img-fluid" style="width:55%;padding-bottom: 0px"></a>
          </div>
          <div class="col-md-6">
            <div class="details">
              <h2 id="Tim_Marks"><a href="https://www.merl.com/people/tmarks" target="_blank" rel="noopener noreferrer">Tim Marks</a></h2>
              <p>Mitsubishi Electric Research Laboratories (MERL)</p>
              <div class="social">

                <!-- <a href=""><i class="fa fa-twitter"></i></a> -->
                <!-- <a href=""><i class="fa fa-facebook"></i></a> -->
                <!-- <a href=""><i class="fa fa-google-plus"></i></a> -->
                <a href="https://www.linkedin.com/in/tim-marks-063894132/" target="_blank" rel="noopener noreferrer"><i class="fa fa-linkedin"></i></a>
              </div>
              <p>Bio:<br>Dr. Tim Marks is a Senior Principal Research Scientist at Mitsubishi Electric Research Labs (MERL) in Cambridge, MA. Prior to joining MERL in 2008, he did postdoctoral research in robotic Simultaneous Localization and Mapping in collaboration with NASA's Jet Propulsion Laboratory. His research at MERL spans a variety of areas in computer vision and machine learning, including face recognition under variations in pose and lighting, and robotic vision and touch-based registration for industrial automation.</p>
            </div>
          </div>  
        </div>
		
		<p></p>
		
		<div class="row">
          <div class="col-md-6">
            <a href="https://www.linkedin.com/in/joanna-matthiesen-61a52a35/" target="_blank" rel="noopener noreferrer"><img src="img/organizers/Joanna_Matthiesen.jpg" alt="Joanna Matthiesen" class="img-fluid" style="width:55%;padding-bottom: 0px"></a>
          </div>
          <div class="col-md-6">
            <div class="details">
              <h2 id="Joanna_Matthiesen"><a href="https://www.linkedin.com/in/joanna-matthiesen-61a52a35/" target="_blank" rel="noopener noreferrer">Joanna Matthiesen</a></h2>
              <p>Math Kangaroo USA, Association Kangourou sans Frontières, Notre Dame University</p>
              <div class="social">

                <!-- <a href=""><i class="fa fa-twitter"></i></a> -->
                <a href="https://www.facebook.com/joanna.lasekmatthiesen/" target="_blank" rel="noopener noreferrer"><i class="fa fa-facebook"></i></a>
                <!-- <a href=""><i class="fa fa-google-plus"></i></a> -->
                <a href="https://www.linkedin.com/in/joanna-matthiesen-61a52a35" target="_blank" rel="noopener noreferrer"><i class="fa fa-linkedin"></i></a>
              </div>
              <p>Bio:<br>Joanna Matthiesen is the president, CEO and co-founder of Math Kangaroo USA, a nationwide nonprofit with a focus on promoting the love of mathematics among students of all ages. Her focus is to help students gain in their interest in mathematics and logic, and in turn, use their skills to make the world a better place. She is passionate about the use of Kangaroo problems to challenge students in both creative thinking and advanced intellectual development. She serves on the International Board of the Association Kangourou sans Frontières to oversee its governance, policy, and annual question selection. Previously, she spent 12 years as a mathematics instructor at various charter high schools in Chicago and Los Angeles, as well as Roosevelt University and City Colleges in Chicago. Joanna holds a Masters in Mathematics from Holy Cross University in Poland, and recently (2022) graduated with honors from the University of Notre Dame with an Executive Masters of Nonprofit Administration. She is fascinated with developing the use of AI in solving simple and complex math and logic problems.</p>
            </div>
          </div>  
        </div>
		
		<p></p>
		
		<div class="row">
          <div class="col-md-6">
            <a href="http://web.mit.edu/cocosci/josh.html" target="_blank" rel="noopener noreferrer"><img src="img/organizers/Joshua_Tenenbaum.jpg" alt="Joshua Tenenbaum" class="img-fluid" style="width:55%;padding-bottom: 0px"></a>
          </div>
          <div class="col-md-6">
            <div class="details">
              <h2 id="Joshua_Tenenbaum"><a href="http://web.mit.edu/cocosci/josh.html" target="_blank" rel="noopener noreferrer">Joshua B. Tenenbaum</a></h2>
              <p>MIT</p>
              <div class="social">
                <!-- <a href=""><i class="fa fa-twitter"></i></a> -->
                <!-- <a href=""><i class="fa fa-facebook"></i></a> -->
                <!-- <a href=""><i class="fa fa-google-plus"></i></a> -->
                <!-- <a href=""><i class="fa fa-linkedin"></i></a> -->
              </div>
              <p>Bio:<br>Prof. Joshua B. Tenenbaum is a Professor of Computational Cognitive Science in the Dept. of Brain and Cognitive Sciences at MIT, a principal investigator at MIT's Computer Science and Artificial Intelligence Laboratory (CSAIL), and a thrust leader in the Center for Brains, Minds and Machines (CBMM). His research centers on perception, learning, and common-sense reasoning in humans and machines, with the twin goals of better understanding human intelligence in computational terms and building more human-like intelligence in machines. The machine learning and artificial intelligence algorithms developed by his group are used by hundreds of science and engineering groups around the world. Tenenbaum received his PhD from MIT in 1999, and was an Assistant Professor at Stanford University from 1999 to 2002 before returning to MIT. His papers have received awards at the Cognitive Science (CogSci), Computer Vision and Pattern Recognition (CVPR), and NeurIPS, among others. He has given invited keynote talks at all of the major machine learning and artificial conferences. He is the recipient of the Early Investigator Award from the Society of Experimental Psychologists, the Distinguished Scientific Award for Early Career Contribution to Psychology from the American Psychological Association, and the Troland Research Award from the National Academy of Sciences, and is a fellow of the Society of Experimental Psychologists and the Cognitive Science Society. He has been involved as a program committee member/chair and/or has co-organized several workshops at machine learning, computer vision and cognitive science venues.</p>
            </div>
          </div>  
        </div>


      </div>

    </section>

  </main>


  <!--==========================
    Footer
  ============================-->
  <footer id="footer">
  <!--
    <div class="footer-top">
      <div class="container">
        <div class="row">

          <div class="col-lg-3 col-md-6 footer-info">
            <img src="img/logo.png" alt="TheEvenet">
            <p>In alias aperiam. Placeat tempore facere. Officiis voluptate ipsam vel eveniet est dolor et totam porro. Perspiciatis ad omnis fugit molestiae recusandae possimus. Aut consectetur id quis. In inventore consequatur ad voluptate cupiditate debitis accusamus repellat cumque.</p>
          </div>

          <div class="col-lg-3 col-md-6 footer-links">
            <h4>Useful Links</h4>
            <ul>
              <li><i class="fa fa-angle-right"></i> <a href="#">Home</a></li>
              <li><i class="fa fa-angle-right"></i> <a href="#">About us</a></li>
              <li><i class="fa fa-angle-right"></i> <a href="#">Services</a></li>
              <li><i class="fa fa-angle-right"></i> <a href="#">Terms of service</a></li>
              <li><i class="fa fa-angle-right"></i> <a href="#">Privacy policy</a></li>
            </ul>
          </div>

          <div class="col-lg-3 col-md-6 footer-links">
            <h4>Useful Links</h4>
            <ul>
              <li><i class="fa fa-angle-right"></i> <a href="#">Home</a></li>
              <li><i class="fa fa-angle-right"></i> <a href="#">About us</a></li>
              <li><i class="fa fa-angle-right"></i> <a href="#">Services</a></li>
              <li><i class="fa fa-angle-right"></i> <a href="#">Terms of service</a></li>
              <li><i class="fa fa-angle-right"></i> <a href="#">Privacy policy</a></li>
            </ul>
          </div>

          <div class="col-lg-3 col-md-6 footer-contact">
            <h4>Contact Us</h4>
            <p>
              A108 Adam Street <br>
              New York, NY 535022<br>
              United States <br>
              <strong>Phone:</strong> +1 5589 55488 55<br>
              <strong>Email:</strong> info@example.com<br>
            </p>

            <div class="social-links">
              <a href="#" class="twitter"><i class="fa fa-twitter"></i></a>
              <a href="#" class="facebook"><i class="fa fa-facebook"></i></a>
              <a href="#" class="instagram"><i class="fa fa-instagram"></i></a>
              <a href="#" class="google-plus"><i class="fa fa-google-plus"></i></a>
              <a href="#" class="linkedin"><i class="fa fa-linkedin"></i></a>
            </div>

          </div>

        </div>
      </div>
    </div>
	-->
	
    <div class="container">
      <div class="copyright">
        &copy; Copyright <strong>TheEvent & VLAR 2023</strong>. All Rights Reserved
      </div>
      <div class="credits">
        <!--
          All the links in the footer should remain intact.
          You can delete the links only if you purchased the pro version.
          Licensing information: https://bootstrapmade.com/license/
          Purchase the pro version with working PHP/AJAX contact form: https://bootstrapmade.com/buy/?theme=TheEvent
        -->
        Designed by <a href="https://bootstrapmade.com/" target="_blank" rel="noopener noreferrer">BootstrapMade</a>
      </div>
    </div>
  </footer><!-- #footer -->

  <a href="#" class="back-to-top"><i class="fa fa-angle-up"></i></a>

  <!-- JavaScript Libraries -->
  <script src="lib/jquery/jquery.min.js"></script>
  <script src="lib/jquery/jquery-migrate.min.js"></script>
  <script src="lib/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="lib/easing/easing.min.js"></script>
  <script src="lib/superfish/hoverIntent.js"></script>
  <script src="lib/superfish/superfish.min.js"></script>
  <script src="lib/wow/wow.min.js"></script>
  <script src="lib/venobox/venobox.min.js"></script>
  <script src="lib/owlcarousel/owl.carousel.min.js"></script>

  <!-- Contact Form JavaScript File -->
  <script src="contactform/contactform.js"></script>

  <!-- Template Main Javascript File -->
  <script src="js/main.js"></script>
</body>

</html>
